# -*- coding: utf-8 -*-
"""Mixed_Nuts_fixed_loop.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fiHPvs0eJ-chnCM8hh72JcCZGQxPM0v8
"""

import torch

results = torch.load("/content/sample_data/logits_results_pretrained.pt")

def extract_correct_predictions(results):
    # Initialize dictionaries to store correct predictions
    correct_predictions = {
        'clean_model': {
            'clean_images': [],
            'adv_linf_images': [],
            'adv_l2_images': []
        },
        'robust_model': {
            'clean_images': [],
            'adv_linf_images': [],
            'adv_l2_images': []
        }
    }

    std_logits = torch.zeros((len(results)*3,results[0]['Clean Logits Clean Model'].shape[0]))
    robust_logits = torch.zeros((len(results)*3,results[0]['Clean Logits Clean Model'].shape[0]))
    true_labels = torch.zeros(len(results)*3)

    mask_correct_rob_on_adv = []
    mask_wrong_rob_on_clean = []
    i = 0

    for item in results:
        true_label = item["True Label"]

        true_labels[3*i] = true_label
        true_labels[3*i+1] = true_label
        true_labels[3*i+2] = true_label

        # Check correct predictions for clean model
        clean_model_clean_logits = item["Clean Logits Clean Model"]
        std_logits[3*i] = clean_model_clean_logits
        clean_model_clean_pred = clean_model_clean_logits.argmax().item()
        if clean_model_clean_pred == true_label:
            correct_predictions['clean_model']['clean_images'].append(item)

        clean_model_adv_linf_logits = item["Adv Linf Logits Clean Model"]
        std_logits[3*i+1] = clean_model_adv_linf_logits
        clean_model_adv_linf_pred = clean_model_adv_linf_logits.argmax().item()
        if clean_model_adv_linf_pred == true_label:
            correct_predictions['clean_model']['adv_linf_images'].append(item)

        clean_model_adv_l2_logits = item["Adv L2 Logits Clean Model"]
        std_logits[3*i+2] = clean_model_adv_l2_logits
        clean_model_adv_l2_pred = clean_model_adv_l2_logits.argmax().item()
        if clean_model_adv_l2_pred == true_label:
            correct_predictions['clean_model']['adv_l2_images'].append(item)


        # Check correct predictions for robust model
        robust_model_clean_logits = item["Clean Logits Robust Model"]
        robust_logits[3*i] = robust_model_clean_logits
        robust_model_clean_pred = robust_model_clean_logits.argmax().item()
        if robust_model_clean_pred == true_label:
            correct_predictions['robust_model']['clean_images'].append(item)
        else :
            mask_wrong_rob_on_clean.append(3*i)

        robust_model_adv_linf_logits = item["Adv Linf Logits Robust Model"]
        robust_logits[3*i+1] = robust_model_adv_linf_logits
        robust_model_adv_linf_pred = robust_model_adv_linf_logits.argmax().item()
        if robust_model_adv_linf_pred == true_label:
            correct_predictions['robust_model']['adv_linf_images'].append(item)
            mask_correct_rob_on_adv.append(3*i+1)


        robust_model_adv_l2_logits = item["Adv L2 Logits Robust Model"]
        robust_logits[3*i+2] = robust_model_adv_l2_logits
        robust_model_adv_l2_pred = robust_model_adv_l2_logits.argmax().item()
        if robust_model_adv_l2_pred == true_label:
            correct_predictions['robust_model']['adv_l2_images'].append(item)
            mask_correct_rob_on_adv.append(3*i+2)

        i+=1

    return correct_predictions,std_logits,robust_logits,true_labels,mask_correct_rob_on_adv,mask_wrong_rob_on_clean

# Usage
# Assuming 'results' is your list of dictionaries from the original code
correct_preds,std_logits,robust_logits,true_labels,mask_correct_rob_on_adv,mask_wrong_rob_on_clean = extract_correct_predictions(results)

# Print summary
print("Clean Model Correct Predictions:")
print(f"Clean Images: {len(correct_preds['clean_model']['clean_images'])}")
print(f"Adversarial Linf Images: {len(correct_preds['clean_model']['adv_linf_images'])}")
print(f"Adversarial L2 Images: {len(correct_preds['clean_model']['adv_l2_images'])}")

print("\nRobust Model Correct Predictions:")
print(f"Clean Images: {len(correct_preds['robust_model']['clean_images'])}")
print(f"Adversarial Linf Images: {len(correct_preds['robust_model']['adv_linf_images'])}")
print(f"Adversarial L2 Images: {len(correct_preds['robust_model']['adv_l2_images'])}")

len(mask_wrong_rob_on_clean)

(std_logits[::3].argmax(dim=1) == true_labels[::3]).sum()

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np

# Helper functions
def layer_normalization(logits,mean,std):
    """Apply layer normalization to logits."""
    #mean = logits.mean(dim=1, keepdim=True)
    #std = logits.std(dim=1, keepdim=True)
    return (logits - mean) / (std + 1e-5)

def nonlinear_transform(logits, s, p, c,mean,std, clamp_fn=F.gelu):
    """
    Nonlinear logit transformation: h_M(s, p, c)
    Parameters:
        logits: Raw logits
        s: Scaling factor
        p: Power exponent
        c: Bias
        clamp_fn: Clamping function (default GELU)
    Returns:
        Transformed logits
    """
    logits = layer_normalization(logits,mean,std)
    logits = clamp_fn(logits + c)
    logits = s * torch.pow(torch.abs(logits), p) * torch.sign(logits)
    return logits

def mix_logits(accurate_logits, robust_logits, alpha):
    """
    Mix logits from accurate and robust models.
    Parameters:
        accurate_logits: Logits from the accurate model
        robust_logits: Transformed logits from the robust model
        alpha: Mixing weight
    Returns:
        Mixed logits
    """
    accurate_probs = F.softmax(accurate_logits, dim=1)
    robust_probs = F.softmax(robust_logits, dim=1)
    mixed_probs = (1 - alpha) * accurate_probs + alpha * robust_probs
    return torch.log(mixed_probs)


def compute_quantile(data, beta):
    """
    Compute the 1-Beta quantile

    Parameters:
    data (torch.Tensor): Input vector
    beta (float): Quantile parameter (0 < beta < 1)

    Returns:
    float: The 1-Beta quantile value
    """
    # Convert to numpy for quantile calculation
    data_np = data.numpy()
    return np.quantile(data_np, 1 - beta)

robust_logits,true_labels,mask_correct_rob_on_adv,mask_wrong_rob_on_clean
from tqdm.notebook import tqdm



def optimize_parameters(beta, s_range, p_range, c_range,
                        std_logits,robust_logits,true_labels,
                        mask_correct_rob_on_adv,mask_wrong_rob_on_clean
):
    """
    Optimize s, p, c, and alpha using validation data.
    Parameters:
        valid_loader: DataLoader for validation data
        s_range, p_range, c_range, alpha_range: Parameter ranges
        clamp_fn: Clamping function
    Returns:
        Optimal parameters
    """

    mean = robust_logits.mean(dim=1, keepdim=True)
    std = robust_logits.std(dim=1, keepdim=True)

    best_params = None
    best_accuracy = 0

    for s in tqdm(s_range):
        for p in p_range:
            for c in c_range:
                    # Update MixedNUTSNet parameters

                    transformed_robust_logits = nonlinear_transform(robust_logits, s, p, c,mean,std)
                    transformed_robust_logits_correct = transformed_robust_logits[mask_correct_rob_on_adv]
                    transformed_robust_logits_wrong = transformed_robust_logits[mask_wrong_rob_on_clean]

                    top_two_values, _ = torch.topk(transformed_robust_logits_correct, k=2, dim=1)
                    margin = top_two_values[:,0] - top_two_values[:,1]
                    q = compute_quantile(margin, beta)

                    alpha = 1/(1+q)
                    mixed_logits = mix_logits(std_logits[mask_wrong_rob_on_clean], transformed_robust_logits_wrong, alpha)
                    predictions = mixed_logits.argmax(dim=1)

                    # Calculate accuracy
                    accuracy = (predictions == true_labels[mask_wrong_rob_on_clean]).sum().item()/len(mask_wrong_rob_on_clean)
                    #print(f"Accuracy: {accuracy}")

                    if accuracy > best_accuracy:
                        best_accuracy = accuracy
                        best_params = (s, p, c, alpha)

    return best_params, best_accuracy

beta = 0.9
s_range = [0.1,0.5,1]
p_range = [0.1,0.5,1]
c_range = [0.1,0.5,1]


optimize_parameters(beta, s_range, p_range, c_range,
                        std_logits,robust_logits,true_labels,
                        mask_correct_rob_on_adv,mask_wrong_rob_on_clean
)

beta = 0
s_range = [0.1,0.5,1]
p_range = [0.1,0.5,1]
c_range = [0.1,0.5,1]


optimize_parameters(beta, s_range, p_range, c_range,
                        std_logits,robust_logits,true_labels,
                        mask_correct_rob_on_adv,mask_wrong_rob_on_clean
)

beta =
s_range = np.arange(-5,5,1)
p_range = np.arange(-5,5,1)
c_range = np.arange(-5,5,1)

mean = robust_logits.mean(dim=1, keepdim=True)
std = robust_logits.std(dim=1, keepdim=True)
(s, p, c, alpha),_ = optimize_parameters(beta, s_range, p_range, c_range,
                        std_logits,robust_logits,true_labels,
                        mask_correct_rob_on_adv,mask_wrong_rob_on_clean)
transformed_robust_logits = nonlinear_transform(robust_logits, s, p, c,mean,std)
mixed_logits = mix_logits(std_logits, transformed_robust_logits, alpha)
clean = (mixed_logits[::3].argmax(dim=1) == true_labels[::3]).sum()
Linf = (mixed_logits[1::3].argmax(dim=1) == true_labels[1::3]).sum()
L2 = (mixed_logits[2::3].argmax(dim=1) == true_labels[2::3]).sum()
print("Clean",clean/10000)
print("Linf",Linf/10000)
print("L2",L2/10000)
print("AGG",(L2+ Linf)/20000)

beta_L = [0,0.7,0.8,1]
result = []
for beta in beta_L:
  s_range = np.arange(-5,5,0.5)
  p_range = np.arange(-5,5,0.5)
  c_range = np.arange(-5,5,0.5)

  mean = robust_logits.mean(dim=1, keepdim=True)
  std = robust_logits.std(dim=1, keepdim=True)
  (s, p, c, alpha),_ = optimize_parameters(beta, s_range, p_range, c_range,
                          std_logits,robust_logits,true_labels,
                          mask_correct_rob_on_adv,mask_wrong_rob_on_clean)
  transformed_robust_logits = nonlinear_transform(robust_logits, s, p, c,mean,std)
  mixed_logits = mix_logits(std_logits, transformed_robust_logits, alpha)
  print(beta)
  clean = (mixed_logits[::3].argmax(dim=1) == true_labels[::3]).sum()
  Linf = (mixed_logits[1::3].argmax(dim=1) == true_labels[1::3]).sum()
  L2 = (mixed_logits[2::3].argmax(dim=1) == true_labels[2::3]).sum()
  print("Clean",clean/10000)
  print("Linf",Linf/10000)
  print("L2",L2/10000)
  print("AGG",(L2+ Linf)/20000)

  result.append((beta,(clean/10000,Linf/10000,L2/10000,(L2+ Linf)/20000)))

clean = (std_logits[::3].argmax(dim=1) == true_labels[::3]).sum()/10000
clean_adv = (std_logits[2::3].argmax(dim=1) == true_labels[2::3]).sum()/10000

rob = (robust_logits[::3].argmax(dim=1) == true_labels[::3]).sum()/10000
rob_adv = (robust_logits[2::3].argmax(dim=1) == true_labels[2::3]).sum()/10000

acc =  [clean,rob]
rob = [clean_adv,rob_adv]

exp_acc = []
exp_rob = []

for e in result:
  exp_acc.append(e[1][0])
  exp_rob.append(e[1][2])

import matplotlib.pyplot as plt
plt.scatter(acc,rob,c='r')
plt.scatter(exp_acc[1:],exp_rob[1:],c='b')
plt.plot(exp_acc[1:],exp_rob[1:],c='b')

std_logits = torch.zeros((len(results)*3,results[0]['Clean Logits Clean Model'].shape[0]))
robust_logits = torch.zeros((len(results)*3,results[0]['Clean Logits Clean Model'].shape[0]))